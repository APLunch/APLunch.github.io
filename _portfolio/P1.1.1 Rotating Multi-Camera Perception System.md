---
title: "Rotating Multi-Camera Perception System"
excerpt: "A dynamically calibrated, behavior-tree–integrated rotating camera pole enabling full 360° coverage, safer manipulation, and 15% throughput gains. <br/><span style='position:relative;display:inline-block;max-width:500px;'><img src='/images/rotating_pole.gif' style='width:100%;filter:blur(10px);' alt='Rotating camera pole (blurred)'/><span style='position:absolute;inset:0;display:flex;align-items:center;justify-content:center;'><span style='background:rgba(0,0,0,0.65);color:#fff;padding:6px 10px;font-weight:700;letter-spacing:0.08em;border:2px solid rgba(255,255,255,0.65);'>CONFIDENTIAL</span></span></span>"
collection: portfolio
---

<!-- Media redacted for patent filing (original GIF kept in repo, but blurred in-page) -->
<div style="position: relative; display: inline-block; max-width: 600px;">
  <img src="/images/rotating_pole.gif" style="width: 100%; filter: blur(10px);" alt="Rotating camera pole (blurred)" />
  <div style="position: absolute; inset: 0; display: flex; align-items: center; justify-content: center;">
    <div style="background: rgba(0,0,0,0.65); color: #fff; padding: 10px 14px; font-weight: 700; letter-spacing: 0.08em; border: 2px solid rgba(255,255,255,0.65);">
      CONFIDENTIAL
    </div>
  </div>
</div>

<div style="position: relative; display: inline-block; max-width: 600px; margin-top: 10px;">
  <img src="/images/rotating_pole_auto_calibration.gif" style="width: 100%; filter: blur(10px);" alt="Auto calibration (blurred)" />
  <div style="position: absolute; inset: 0; display: flex; align-items: center; justify-content: center;">
    <div style="background: rgba(0,0,0,0.65); color: #fff; padding: 10px 14px; font-weight: 700; letter-spacing: 0.08em; border: 2px solid rgba(255,255,255,0.65);">
      CONFIDENTIAL
    </div>
  </div>
</div>

## Objective
Pixmo’s manipulation workspace contains significant blind spots due to the robot’s geometry, mounted accessories, and customer-specific environments. These occlusions limit perception, reduce planner confidence, and prevent aggressive but safe motion profiles.  
The goal of the camera-pole project was to create a **full-workspace, continuously updated 3D perception system**—built on a custom rotating camera pole—providing complete visibility around the robot and enabling safer, faster, and more intelligent behavior planning.

## Technical Summary

### Hardware + System Architecture
A compact motorized camera pole was co-designed with the hardware team and integrated into Pixmo’s sensor stack. The pole rotates multiple calibrated RGB-D camera around the robot, capturing dense 3D observations across the full 360° workspace.

### Calibration Pipeline (Non-Linear Optimization)
I designed and implemented a **two-stage extrinsic calibration pipeline**:
1. **Initial geometric circle-fit estimation** using tracked calibration-board trajectories.  
2. **Levenberg–Marquardt non-linear optimization** over all frames (bundle-adjustment style) solving for:
   - Camera-to-pole transform  
   - Pole axis orientation  
   - Rotation radius + phase  
   - Pole-to-base transform

This produced a high-accuracy model of the camera’s motion, enabling milimeter-level global alignment of every frame.

### Real-Time Perception Stack
On top of the calibrated model, I built the perception system that:
- Reconstructs a **globally aligned 3D panoramic map** as the pole rotates.  
- Generates dense geometry for planner collision checking.  
- Identifies pallet, wall, and conveyor obstacles.  
- Provides continuous spatial updates for motion planning and safety monitors.

### Behavior Tree Integration
The entire pipeline was integrated into Pixmo’s **Behavior Tree (BT)** framework:
- BT nodes trigger camera-pole sweeps during critical behaviors (approach, pick, reorientation, stow).  
- Perception results feed directly into task-level decision logic.  
- Failure handling and fallback states leverage real-time scene updates from the pole.

### Simulation Support for Off-Hardware Development
I built a camera-pole simulation model for our internal dev stack:
- Programmable virtual pole kinematics  
- Synthetic depth + RGB data generation  
- Drop-in replacement for real hardware streams  

This allowed rapid iteration of BT integration, and perception logic **without requiring the physical robot**, accelerating development and reducing hardware downtime.

## Results

- **15% increase in overall system throughput**, enabled by improved planner confidence and reduction in blind-zone slow-downs.  
- **Significantly safer motion execution** due to continuous clearance estimation from dynamic camera sweeps.  
- **Higher task success rates** in cluttered or previously unobservable regions.  
- **Robust simulation-to-real transfer**, shortening development cycles.  
- The camera-pole perception module is now a standard part of Pixmo’s core perception stack.

## Detailed Documentation
*Restricted by non-disclosure agreements.*

